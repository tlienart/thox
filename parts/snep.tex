% !TEX root = ../thesis.tex

\todofr{
	\begin{itemize}
		\item Geometry and KL and mirror descent
		\item trick of the trade when projections don't work and why
	\end{itemize}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distributed Bayesian inference}

In this section we consider the problem of performing Bayesian inference when the relevant data is distributed across different compute nodes. 
Let us assume that there are $K$ such compute nodes each holding independent parts of the data $y_i$ (with $i=1,\dots,K$) such that these parts form a partition of the complete data $y$. 
In a Bayesian setting, we are interested in the posterior distribution over a parameter of interest $x$ given the entire data $y$. We can write this posterior as the product of $K$ terms corresponding to the parts $y_i$: \check{june8}
%
\eqa{
	p(x\st y) &\propto& \pi_0(x) \prod_{i=1}^{K} p(y_i\st x)\label{eq:distrposterior}
}
%
where $\pi_0$ is a prior distribution. Each of the likelihood term itself factors over the individual data points of $y_i$, i.e.: $p(y_i\st x)=\prod_{j=1}^{N_i}p(y_{ij}\st x)$ with $N_i$ the number of individual data points held by the compute node $i$.

\todofr{Add here litt, why is this relevant, some basic stuff that have been tried + references}

Defining $t_i$ to be nonnegative factors with $t_i(x)=p(y_i\st x)$, the factorised form \eqref{eq:distrposterior} reads $\pi_0(x)\prod_{i=1:K}t_i(x)$ which is the form \eqref{eq:targetfactorises} that we had used to motivate the introduction of the ADF and EP algorithms (cf.\ point \ref{s:ADF+EP}).
In the rest of this chapter, we show how different variants of the EP algorithm can be used to perform parallel variational inference in the presence of distributed data.\check{jun8} 

\add{come back to this, add litt for distr bayesian (see SNEP paper), see also confirmation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EP variants for distributed inference}
As indicated in the introductory point, we consider a target distribution of the form $p(x)\propto \pi_0\prod_{i=1:K}t_i(x)$ where the evaluation of one of the $t_i$ requires access to the compute node $i$. The aim is to construct an approximation $q\in\mathcal F_\phi$ parametrised by a vector $\theta$ with
%
\eqa{
	q(x) &=& \pi_0(x)\exp(\scal{\theta,\phi(x)}-A(\theta)) \spe \pi_0(x)\exp(-A(\theta))\prod_{i=1}^{K}\tilde t_i(x)
}
%
where $\tilde t_i(x):=\exp\scal{\omega_i,\phi(x)}$, and therefore: $\sum_{i=1:K}\omega_i=\theta$. The tilted distributions associated with each of the factors are given by
%
\eqa{
	q_i(x) &=& \pi_0(x)t_i(x)\exp(\scal{\lambda_i,\phi(x)}-A_i(\lambda_i))
}
% 
where $\lambda_i=(\theta-\omega_i)$ and $A_i(\lambda_i)$ is the corresponding log-partition function. Much like the log-partition function of $q$, the $A_i$ are convex and $\nabla A_i(\lambda_i)=\E_{q_i}[\phi(X)]$. Indeed, each $A_i$ is simply the log-partition functions of the exponential-family $\mathcal F_\phi$ with respect to a modified base-measure including $t_i$.
In the EP setting, we seek to determine the parameters $\omega_1,\dots,\omega_K$ such that the LMMC \eqref{eq:LMMC} hold, i.e.: $\E_q[\phi(X)]=\E_{q_i}[\phi(X)]$ for each $i=1,\dots,K$.
The general parallel computational framework considered iterates on the following steps:
\begin{enumerate}\itsepa
	\item the master node sends a global parameter $\theta$ to each compute node,
	\item each compute node $i$ attempts to find a new $\omega_i$ such that the corresponding LMMC is (approximately) met and sends the updated $\omega_i$ to the master node,
	\item the master node integrates the new $\omega_i$ into $\theta$.
\end{enumerate} 

As we will see, there are different ways to implement this general framework.
We will show empirically that a determining element in the performance of a particular implementation is its robustness to Monte Carlo noise. 
Indeed, in our general setting we do not assume that computing $\E_{q_i}[\phi(X)]$ can be done exactly. Rather, we assume that it is approximated by a Monte Carlo estimator.\check{june8}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Damped updates in the natural parameter space}
In their paper, \citet{xu14} suggest a method to synchronise Monte Carlo samplers ran on independent compute nodes. They call it \emph{Sequential Moment Sharing} or SMS for short. Effectively, SMS corresponds precisely to the case mentioned at the previous point consisting of running EP across multiple physical nodes while using noisy estimates of $\E_{q_i}[\phi(X)]$, the expected value of the sufficient statistics under the tilted distribution. 
Below, we introduce the algorithm as a damped fixed-point iteration in the natural parameter space. This will prove useful when comparing different EP-like algorithms.\check{june8,may27}\\

We showed that the basic EP algorithm could be interpreted as a kind of fixed point iteration targeting the Local Moment Matching Conditions \eqref{eq:LMMC} (LMMC). At a given step of the algorithm, when considering the inclusion of the factor $t_i$, the global parameter should therefore be updated such as to verify $\E_{q_\theta}[\phi(X)]= \E_{q_i}[\phi(X)]$. Let $\mu_i:=\E_{q_i}[\phi(X)]$, the update then amounts to finding $\theta$ such that $\nabla A(\theta) = \mu_i$ or
%
\eqa{	
	\theta &\leftarrow & \nabla A^{\star}(\mu_i).	\label{eq:ep-np-update}
}
%
In the case where one is considering a Monte Carlo estimator for $\mu_i$, these updates are inexact and it is crucial to mitigate the effect of the noise by considering \emph{damped updates}.\add{would be good to come back further to this when considering the gaussian case (inversion of noisy matrix), mention it in discussion} In fact, even when one uses the exact $\mu_i$, it can be beneficial to the overall convergence of the algorithm to consider damped updates \citep{heskes03}. Damping \eqref{eq:ep-np-update} leads to the modified update:\check{may11}
%
\eqa{
	\theta &\leftarrow & (1-\kappa)\theta + \kappa \nabla A^{\star}(\hat\mu_i),\label{eq:damped-update-np}
}
%
where $\kappa \in(0,1]$ is the damping parameter and $\hat\mu_i$ is an estimator for $\mu_i$. As in the gradient descent algorithm, the damping parameter can be decreased over iterations according to a schedule in order to further help convergence.\add{We will explore the connection to GD in more details later}
The damped update \eqref{eq:damped-update-np} can also be expressed in terms of the $\omega_i$ (parameter of the factor approximation $\tilde t_i$) and the $\lambda_i$ (parameter of the corresponding cavity):\check{june8}
%
\eqa{
	\omega_i &\leftarrow& \omega_i + \kappa(\nabla A^{\star}(\hat\mu_i)-\lambda_i).\label{eq:damped-update-np-w}
}
%
One can also swap the role of $\lambda_i$ and $\omega_i$ and obtain another valid damped update mechanism. Both forms are amenable to parallelisation since they can be expressed solely in terms of local parameters attached to the $i$th compute node.\add{review statement, potentially in lambdai less stable because cavity collapse but should check if can explain why}\check{june8,may27}\\

The basic SMS algorithm operates synchronous updates.
At step $k$, each node receives the current global parameter $\theta$ and computes the parameter corresponding to the current tilted distribution $q_i$ i.e.: $\lambda_i=(\theta-\omega_i)$. Each node then forms a Monte Carlo estimator $\hat\mu_i$ of $\E_{q_i}[\phi(X)]$, computes the damped step \eqref{eq:damped-update-np-w} and returns the updated local parameter $\omega_i$ to the master node. 
The master node then aggregates all updated local parameters and updates the global parameter: 
%
\eqa{	\theta &\leftarrow& (1-\kappa')\theta+\kappa'\sum_{i=1}^{K}\omega_{i}	}
%
where $\kappa' \in (0,1]$ is a global damping parameter which may also help convergence. 
These steps are summarised at the algorithm \ref{alg:ep-sms-synch} below.\check{june8}

\begin{algorithm}[!h]\small
	\caption{\label{alg:ep-sms-synch}\dblue{\emph{\small Sequential Moment Sharing (synchronous)}}}
	\begin{algorithmic}[1]
	\State Initialise $\theta,\omega_{1},\dots,\omega_{K}$ such that $\theta=\sum_{i=1}^{K}\omega_{i} \in \Omega$ and send to each compute node
	\For{$k=1:N_{\text{EP}}$}
		\State Send current global parameter $\theta$ to each node
		\For{node $i=1:K$}
			\State Update the cavity parameter $\lambda_{i}\leftarrow\theta-\omega_{i}$
			\State Form an estimator $\hat\mu_{i}$ of $\E_{q_{i}}[\phi(X)]$
			\State Update the local parameter $\omega_{i}\leftarrow\omega_{i}+\kappa(\nabla A^{\star}(\hat\mu_{i})-\lambda_i)$
			\State Send the updated $\omega_{i}$ to the master node
		\EndFor
		\State Update global parameter $\theta\leftarrow (1-\kappa')\theta + \kappa'\sum_{i=1}^{K}\omega_{i}$
	\EndFor\\	
	\Return{$\theta$}
	\end{algorithmic}
\end{algorithm} 

It is easy to see how this algorithm can be altered to accommodate asynchronous updates. Indeed, instead of waiting for all nodes to complete their tasks, each node could asynchronously request the most recent $\theta$ available from the master node while the master node would continuously integrate information it receives from the compute nodes. In fact, each node would then simply send the difference $\delta_{i} = (\omega_{i}^{\text{new}}-\omega_{i}^{\text{old}})$ which can be integrated directly into an update of $\theta$. \check{june8}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Damped updates in the mean parameter space}

The main issue with the SMS algorithm which we will expose in more details in the experiments\add{do it and refer} is that it performs the projection of the noisy estimator $\hat\mu_{i}$ \emph{before} the damping step. Since this projection operator is likely non-linear and potentially numerically unstable this can hinder the performances of the algorithm. In the case of the Gaussian distribution for instance, the projection effectively requires the inversion of a noisy matrix (see \eqref{proj-mp-np-gauss}). It seems therefore sensible to suggest damping the estimator before it gets projected. This leads to going from \eqref{eq:damped-update-np} to
%
\eqa{
\nabla A(\theta) &\leftarrow& (1-\kappa)\nabla A(\theta) + \kappa \hat\mu_{i}
}
%
or, equivalently, to
%
\eqa{
\theta &\leftarrow& \nabla A^{\star}(\nabla A(\theta) + \kappa (\hat\mu_{i}-\nabla A(\theta))).
\label{eq:damped-update-mp}
}
%
Of course, if $\kappa=1$ (no damping), both approaches are equivalent. Anyone familiar with convex optimisation will notice the similarity with the \emph{mirror-descent algorithm} \citep{nemirovski83, beck03}. We will explore and discuss this similarity later.\add{do it} 
In order to have updates that are more amenable to parallelisation, one can compare the update \eqref{eq:damped-update-np-w} with the update \eqref{eq:damped-update-np} in the SMS case and suggest the following algorithm:
%
\eqa{
\omega_{i} &\leftarrow& \nabla A^{\star}(\nabla A(\omega_{i}) + \kappa (\hat\mu_{i}-\nabla A(\theta))).
\label{eq:damped-update-mp}
}
%
\dred{Discuss the other update first, reason about $\lambda_{i}$ collapsing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\dred{SNEP algorithm}}
\todofr{
	\begin{itemize}\itsepa
		\item should explain why there's a problem with SMS in presence of noise (in particular with gaussian case)
		\item should then suggest that damping in MP space is a good idea
		\item then suggest algorithm
		\item then suggest that we will also obtain the same algorithm by looking at energy
	\end{itemize}
}
\subsubsection*{Noisy EP iterations in mean parameter space}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{The SNEP algorithm}

\subsection{\dred{The ``EP energy'' perspective}}
\todofr{
Cite minka, mention energy, explain that it's not really something to increase or decrease but rather want stationary points and that's it, show that if write the KL and get rid of a part then get this energy (essentially use that to show that it's a bit pointless)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Obtaining the energy}
Another perspective to EP is to consider the so-called ``EP Energy''\add{citations}. This ``energy'' is more a function that has the same fixed points as EP than an energy.\add{should probably clarify this or not put this sentence (here)} One way to obtain it is to decompose the KL divergence between $p$ and $q$. First, let us write explicitly the objects considered:\add{This is now REDUNDANT with start}
\begin{itemize}\itsepa
	\item the target distribution $p$ with $p(x)=Z_p\inv \pi_0(x)\prod_{i=1:K}t_i(x)$,
	\item the global approximating distribution $q$ with $q(x)=Z_q\inv \pi_0(x)\exp\scal{\theta,\phi(x)}$ which we can also write $Z_q\inv \pi_0(x)\exp\scal{\sum_{i=1:K}\omega_i,\phi(x)}$ as in \eqref{eq:approxadf},
	\item the tilted distributions $q_i$ with $q_i(x)=Z_i\inv \pi_0(x)\exp\scal{\lambda_i,\phi(x)}t_i(x)$.
\end{itemize}
In the list above, $\pi_0$ is the prior distribution and $Z_p,Z_q$ and $Z_i$ designate normalisation constants. From before, we have $\log Z_q=A(\theta)$ and, in a similar fashion, we can define $A_i(\lambda_i):=\log Z_i$ which enjoy similar property as $A$. In particular, it is convex and $\nabla_{\lambda_i} A_i(\lambda_i) =\mu_{i}$.\footnote{Indeed, $A_i$ is the log partition function associated with $\mathcal F_\phi$ under a modified base-measure.} The parameters of the tilted distributions $\lambda_i$ are given by $\lambda_i=(\theta-\omega_i)$ and hence must be such that $\sum_{i=1:K}\lambda_i=(K-1)\theta$.\\
To simplify notations over the next few equations we omit the dependence in $x$ which is obvious from the context and all sums and products are assumed to go over $i=1,\dots,K$. The KL divergence between $p$ and $q$ can then be written as\check{may15}
%
\eqa{	
	\KL{p,q} &=& \E_p\pac{\log\pat{Z_p\inv\pi_0\prod_{i}t_i}-\log q}	.
\label{eq:decomposeKL}}
%	
Consequently, the product $t_i$ can be manipulated to make the $q_i$ appear:
%
\eqa{
	\prod_{i} t_i &=& \prod_{i}{\pi_0\exp\scal{\lambda_i,\phi}t_i\over \pi_0\exp\scal{\lambda_i,\phi}}\spe {\prod_i Z_iq_i\over \pi_0 (Z_q q)^{K-1},}
}
%
and using this in \eqref{eq:decomposeKL} leads to:\footnote{Note that considering the reverse KL leads to a very similar decomposition:
\[\KL{q,p} - \log Z_p \spe -\mathcal E + \sum_i \KL{q,q_i}.\]}
%
\eqa{
\KL{p,q} + \log Z_p &=& \underbrace{(1-K) A(\theta) + \sum_{i}A_i(\lambda_i)}_{\mathcal E} + \mathbb E_p\pac{\log q_i/q}.
}
%
The first part, denoted by $\mathcal E$ is the \emph{EP energy}.\add{add footnote explaining that sometimes defined with different sign but that it doesn't matter} Note that its gradient in $\lambda_i$ is simply $\nabla_{\lambda_i}\mathcal E = (-\nabla A(\theta) + \mu_{i})$. 
The stationary points of $\mathcal E$ in $\lambda_i$ therefore correspond to the LMMC \eqref{eq:LMMC} that the EP algorithm attempts to satisfy.
It is also interesting to briefly look at the remainder of the right-hand side of \eqref{eq:decomposeKL}. Discarding the terms that don't depend on $\lambda_i$, we have
%
\eqa{
	\nabla_{\lambda_i}\E_p[\log q_i/q] &=& \nabla_{\lambda_i}\E_p\pac{\scal{\lambda_i,\phi}-A_i(\lambda_i)  - \scal{(K-1)\inv\sum_i\lambda_i,\phi}+A(\theta)}\nn\\
	&=& \E_{p}[\phi]-\mu_i-{1\over K-1}\E_{p}[\phi] + {1\over K-1}\nabla A(\theta).
}
%
Therefore the gradient of the complete right hand side of \eqref{eq:decomposeKL} (i.e. the gradient of $\KL{p,q}$) in $\lambda_i$ is in fact proportional to $(\E_{p}[\phi]-\nabla A(\theta))$ leading to the same stationary points as the GMMC \eqref{eq:GMMC}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Looking for a saddle point of the EP energy}
\todofr{Think first about how you want to present information and in particular what you want to say. Could just present the min max problem. Say that if torture the problem you can get to a double loop that looks like SNEP. Would be good not to go along the crappy road of the dev a la Teh, just showing that we're actually doing some kind of Newton's method would already be quite nice use for this \url{http://homes.soic.indiana.edu/classes/spring2012/csci/b553-hauserk/newtons_method.pdf} and probably ``Information geometry of mirror descent'' \citep{raskutti15}}

The energy $\mathcal E$ as a function of $\theta$ and the $\lambda_i$ is given by
\eqa{\mathcal E(\theta,\lambda_1,\dots,\lambda_K)&=& (1-K)A(\theta) + \sum_{i=1}^{K} A_i(\lambda_i)}
under the condition that $\theta=(K-1)\inv \sum_{i=1:K}\lambda_i$. The first term is concave in $\theta$ while each of the terms in the sum is convex in $\lambda_i$. This justifies the interpretation of the EP stationary point as being solutions to the following min-max problem called the \emph{EP dual energy} problem \citep{minka01c}:\add{this part is useful to talk about SEP/BBa potensh}
\eqa{	\min	_\theta\max_{\{\lambda_i\}} \quad(K-1)A(\theta)-\sum_{i=1}^{K}A_i(\lambda_i), \quad \text{s.t.}\quad \theta = (K-1)\inv\sum_{i=1}^{K}\lambda_i.}
\todofr{
Here could add few citations for double loop stuff.
}



\subsection{\dred{Parameter tying, SEP and BBa}}

\subsubsection{BBA}
\dred{DRAFT with energy set to 1}
\eqa{	\mathcal E_{BBA}(\theta,\lambda) &=& (1-K)A(\theta)+\sum_{i=1}^{K}A_i(\lambda)	}
under the condition that $\theta=K\lambda/(K-1)$. The stationary point of BBa 
\eqa{	\nabla A(\theta) &=& K\inv \sum_{i=1}^{K} \nabla A_i(\lambda).	}
(A form of average). 
Key point is that the $\mathcal E_{BBA}$ is bounded from below for $\alpha\le N$ (see BBA) therefore convergence or something.

%%%%%%%%%%%%%%%%%%%%%
\section{Comparisons}
\todofr{Explain primary comparison between SMS and SNEP since parameter tying is a further assumption (or say something of the sorts following Distbayes paper). Redo the experiments from ages ago (see if still has notebooks) comparing different EP approaches for BLR on single machine, discuss. Then discuss in distributed setting (graph from Distbayes paper)}


%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\todofr{
\begin{itemize}
	\item pitfalls of using EP / VB for large dimensional, have to revert to diagonal gaussians in which case maybe not so interesting. As a result and since we are using a large number of points, the uncertainty recovered is often extremely small in both EP and VB and unusable in practice. One may therefore wonder whether a purely optimisation based approach effectively targeting the MAP directly is not all that we can afford etc.
\end{itemize}
}